{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import pathlib\n",
    "from copy import deepcopy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/1nao/GitHub/Gradient_Boosting_Meta_Tree\n"
     ]
    }
   ],
   "source": [
    "ROOT_DIR = pathlib.Path().resolve().parent\n",
    "print(ROOT_DIR)\n",
    "sys.path.append(str(ROOT_DIR))\n",
    "FIG_DIR = ROOT_DIR / 'results' / 'figures'\n",
    "os.makedirs(FIG_DIR, exist_ok=True)\n",
    "ERROR_ARR_SAVE_DIR = ROOT_DIR / 'results' / 'error_array'\n",
    "os.makedirs(ERROR_ARR_SAVE_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gradient_boosting_meta_tree import metatree, normal\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0\n",
    "rng = np.random.default_rng(SEED)\n",
    "np.random.seed(SEED)\n",
    "MODEL_SEED = 0 # Seed for the learnmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ベンチマークデータ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_DATA = ROOT_DIR / 'data' / 'regression' / 'preprocessed_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mpg',\n",
       " 'abalone',\n",
       " 'automobile',\n",
       " 'cpu',\n",
       " 'liver',\n",
       " 'servo',\n",
       " 'student',\n",
       " 'wine_quality']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# フォルダ名一覧から全データ名を取得\n",
    "DATA_NAMES = os.listdir(DIR_DATA)\n",
    "DATA_NAMES = np.sort([d for d in DATA_NAMES if d != '.DS_Store']).tolist()\n",
    "DATA_NAMES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの読み込み"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 関数の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(\n",
    "        data_name: str,\n",
    "        dir_data: str=DIR_DATA,\n",
    "        flag_lr: bool = False,\n",
    "):\n",
    "    # 個人の環境でpathを変更\n",
    "    X_continuous_load = np.load(os.path.join(dir_data,data_name,'x_continuous.npy'))\n",
    "    X_categorical = np.load(os.path.join(dir_data,data_name,'x_categorical.npy')).astype(int)\n",
    "    y = np.load(os.path.join(dir_data,data_name,'y.npy'))\n",
    "\n",
    "    # 連続説明変数の標準化\n",
    "    mean = np.mean(X_continuous_load,axis=0)\n",
    "    std = np.std(X_continuous_load,axis=0)\n",
    "    X_continuous = (X_continuous_load - mean) / std\n",
    "\n",
    "    # 線形回帰で定数項を入れる処理\n",
    "    if flag_lr:\n",
    "        tmp = np.copy(X_continuous)\n",
    "        X_continuous = np.ones([tmp.shape[0],tmp.shape[1]+1])\n",
    "        X_continuous[:,:-1] = tmp\n",
    "\n",
    "    #標準化の処理\n",
    "    y = (y - y.mean()) / y.std()\n",
    "\n",
    "    return X_continuous, X_categorical, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mpg 392 11\n",
      "abalone 4177 10\n",
      "automobile 159 57\n",
      "cpu 209 36\n",
      "liver 345 5\n",
      "servo 167 12\n",
      "student 395 43\n",
      "wine_quality 4898 11\n"
     ]
    }
   ],
   "source": [
    "# すべてのデータのサンプル数と説明変数の数を確認\n",
    "for data_name in DATA_NAMES:\n",
    "    x_continuous,x_categorical,y = load_data(data_name,DIR_DATA)\n",
    "    print(data_name, x_continuous.shape[0], x_continuous.shape[1] + x_categorical.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習と指標計算を行う関数作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 関数の定義順の都合上木の数をここで指定\n",
    "num_tree = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_h_params_learnmodel = {\n",
    "    'h0_tau_x': 1e1,\n",
    "    'h0_m': 0.,\n",
    "    'h0_tau': 1e0,\n",
    "    'known_precision': True,\n",
    "}\n",
    "max_depth = 3 # change here in 3,5,15 and rerun to have each result\n",
    "h0_split = 0.8\n",
    "learning_rate = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MTGB_model_dict = {\n",
    "    'model': metatree.SumOfMetaTreeLearnModel,\n",
    "    'model_type': 'metatree',\n",
    "    'init_params': {\n",
    "        'c_num_metatrees': num_tree,\n",
    "        'SubModel': normal,\n",
    "        'sub_h0_params': sub_h_params_learnmodel,\n",
    "        'c_max_depth': max_depth,\n",
    "        'h0_split': h0_split,\n",
    "        'learning_rate': learning_rate,\n",
    "        'seed': MODEL_SEED,\n",
    "    },\n",
    "    'build_params': {\n",
    "        'split_strategy': 'best',\n",
    "        'building_scheme': 'depth_first',\n",
    "        'calc_residual': True,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_measure_performance_gb(\n",
    "        x_continuous_train, x_categorical_train, y_train,\n",
    "        x_continuous_test, x_categorical_test, y_test,\n",
    "        num_tree,\n",
    "):\n",
    "    x_train = np.concatenate([x_continuous_train, x_categorical_train], axis=1)\n",
    "    x_test = np.concatenate([x_continuous_test, x_categorical_test], axis=1)\n",
    "\n",
    "    gb = GradientBoostingRegressor(n_estimators=num_tree, learning_rate=learning_rate, max_depth=max_depth, random_state=MODEL_SEED)\n",
    "    gb.fit(x_train, y_train)\n",
    "    hat_y_train = gb.predict(x_train)\n",
    "    hat_y_test = gb.predict(x_test)\n",
    "\n",
    "    train_mse = mean_squared_error(y_train, hat_y_train)\n",
    "    test_mse = mean_squared_error(y_test, hat_y_test)\n",
    "    return train_mse, test_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_measure_performance_mtgb(\n",
    "        x_continuous_train, x_categorical_train, y_train,\n",
    "        x_continuous_test, x_categorical_test, y_test,\n",
    "        num_tree,\n",
    "):\n",
    "        data_info = {\n",
    "                'c_dim_continuous': x_continuous_train.shape[1],\n",
    "                'c_dim_categorical': x_categorical_train.shape[1],\n",
    "        }\n",
    "        init_inputs = {\n",
    "                **MTGB_model_dict['init_params'],\n",
    "                **data_info,\n",
    "        }\n",
    "\n",
    "        build_inputs = {\n",
    "                **MTGB_model_dict['build_params'],\n",
    "                'x_continuous_vecs': x_continuous_train,\n",
    "                'x_categorical_vecs': x_categorical_train,\n",
    "                'y_vec': y_train,\n",
    "        }\n",
    "        model = MTGB_model_dict['model'](**init_inputs)\n",
    "        model.build_metatrees(**build_inputs)\n",
    "        # model.calc_pred_dist()\n",
    "\n",
    "        hat_y_train = model.make_prediction(\n",
    "                x_continuous_train,\n",
    "                x_categorical_train,\n",
    "                loss='squared',\n",
    "        )\n",
    "        hat_y_test = model.make_prediction(\n",
    "                x_continuous_test,\n",
    "                x_categorical_test,\n",
    "                loss='squared',\n",
    "        )\n",
    "\n",
    "        train_mse = mean_squared_error(y_train, hat_y_train)\n",
    "        test_mse = mean_squared_error(y_test, hat_y_test)\n",
    "        \n",
    "        root_split_proba_list = [None for _ in model.hn_metatree_list]\n",
    "        for i, metatree in enumerate(model.hn_metatree_list):\n",
    "                root_split_proba_list[i] = metatree.root_node.hn_split\n",
    "\n",
    "        return train_mse, test_mse, root_split_proba_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "def roop_kfold(\n",
    "        data_name,\n",
    "        num_tree,\n",
    "        modelname,\n",
    "        # do_metatree,\n",
    "        visualize,\n",
    "        num_cv=3,\n",
    "        num_folds=5,\n",
    "):\n",
    "        num_trials = num_cv * num_folds\n",
    "        x_continuous,x_categorical,y = load_data(data_name,DIR_DATA)\n",
    "        \n",
    "        # load mse list from ERROR_ARR_SAVE_DIR\n",
    "        # try:\n",
    "        #         train_mse_list = list(np.load(ERROR_ARR_SAVE_DIR / f'{data_name}_{modelname}_train_mse.npy'))\n",
    "        #         test_mse_list = list(np.load(ERROR_ARR_SAVE_DIR / f'{data_name}_{modelname}_test_mse.npy'))\n",
    "        # except:\n",
    "        #         # tqdm.write(f'No file found. Create new list.')\n",
    "        #         train_mse_list = []\n",
    "        #         test_mse_list = []\n",
    "        train_mse_list = []\n",
    "        test_mse_list = []\n",
    "        if modelname in ['MTGB']:\n",
    "                root_split_proba_list_list = []\n",
    "\n",
    "        with tqdm(total=num_cv, desc=f'{num_cv}CV', leave=False) as bar1:\n",
    "                for i in range(num_cv):\n",
    "                        with tqdm(total=num_folds, desc=f'{num_folds} folds', leave=False) as bar2:\n",
    "                                kf = KFold(n_splits=num_folds, shuffle=True, random_state=SEED+i)\n",
    "                                for j, (train_index, test_index) in enumerate(kf.split(y)):\n",
    "                                        x_continuous_train, x_continuous_test = x_continuous[train_index], x_continuous[test_index]\n",
    "                                        x_categorical_train, x_categorical_test = x_categorical[train_index], x_categorical[test_index]\n",
    "                                        y_train, y_test = y[train_index], y[test_index]\n",
    "                                        if  modelname == 'GB':\n",
    "                                                train_mse, test_mse = pred_measure_performance_gb(\n",
    "                                                        x_continuous_train, x_categorical_train, y_train,\n",
    "                                                        x_continuous_test, x_categorical_test, y_test,\n",
    "                                                        num_tree=num_tree,\n",
    "                                                )\n",
    "                                                train_mse_list.append(train_mse)\n",
    "                                                test_mse_list.append(test_mse)\n",
    "                                                bar2.update(1)\n",
    "                                        elif modelname == 'MTGB':\n",
    "                                                train_mse, test_mse, root_split_proba_list = pred_measure_performance_mtgb(\n",
    "                                                        x_continuous_train, x_categorical_train, y_train,\n",
    "                                                        x_continuous_test, x_categorical_test, y_test,\n",
    "                                                        num_tree=num_tree,\n",
    "                                                )\n",
    "                                                train_mse_list.append(train_mse)\n",
    "                                                test_mse_list.append(test_mse)\n",
    "                                                root_split_proba_list_list.append(root_split_proba_list)\n",
    "                                                bar2.update(1)\n",
    "                                        else:\n",
    "                                                raise ValueError('modelname is invalid')\n",
    "                        bar1.update(1)\n",
    "        np.save(ERROR_ARR_SAVE_DIR / f'{data_name}_{modelname}{num_tree}_depth{max_depth}_train_mse.npy', np.array(train_mse_list))\n",
    "        np.save(ERROR_ARR_SAVE_DIR / f'{data_name}_{modelname}{num_tree}_depth{max_depth}_test_mse.npy', np.array(test_mse_list))\n",
    "        if modelname == 'MTGB':\n",
    "                np.save(ERROR_ARR_SAVE_DIR / f'{data_name}_{modelname}{num_tree}_depth{max_depth}_root_split_proba_list.npy', np.array(root_split_proba_list_list))\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## execute roops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELNAME_LIST = [\n",
    "    'MTGB',\n",
    "    'GB',\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(\n",
    "    data_name,\n",
    "    num_tree,\n",
    "    visualize,\n",
    "    num_cv,\n",
    "    num_folds,\n",
    "):\n",
    "    with tqdm(total=len(MODELNAME_LIST), desc=\"Model\", leave=False) as pbar:\n",
    "        for modelname in MODELNAME_LIST:\n",
    "            txt = f'{data_name}: model = {modelname}'\n",
    "            pbar.set_postfix_str(txt)\n",
    "            roop_kfold(\n",
    "                data_name,\n",
    "                num_tree,\n",
    "                modelname,\n",
    "                visualize,\n",
    "                num_cv,\n",
    "                num_folds,\n",
    "            )\n",
    "            pbar.update(1)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mpg',\n",
       " 'abalone',\n",
       " 'automobile',\n",
       " 'cpu',\n",
       " 'liver',\n",
       " 'servo',\n",
       " 'student',\n",
       " 'wine_quality']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_cv: 3, num_folds: 5, visualize: False, num_tree: 100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb959e18805749d3bf3b6a2cd6374590",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Data:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3e653b13a6045b7a69bb0d209ec9990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Model:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ada2709df7b4cfa9b1897e22cbf7674",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "3CV:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d977914efe684c4685057687e31f2a50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "5 folds:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d67375b2c844ce8b147c57d4716cc66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "5 folds:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e101d535e4c40eaad4043a5ba254b34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "5 folds:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m txt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx_continuous\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m samples, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx_continuous\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m+\u001b[39mx_categorical\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     11\u001b[0m pbar\u001b[38;5;241m.\u001b[39mset_postfix_str(txt)\n\u001b[0;32m---> 12\u001b[0m res_dict \u001b[38;5;241m=\u001b[39m \u001b[43mexperiment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_tree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_cv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_folds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[17], line 12\u001b[0m, in \u001b[0;36mexperiment\u001b[0;34m(data_name, num_tree, visualize, num_cv, num_folds)\u001b[0m\n\u001b[1;32m     10\u001b[0m         txt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: model = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodelname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     11\u001b[0m         pbar\u001b[38;5;241m.\u001b[39mset_postfix_str(txt)\n\u001b[0;32m---> 12\u001b[0m         \u001b[43mroop_kfold\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_tree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodelname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_cv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_folds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m         pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[15], line 45\u001b[0m, in \u001b[0;36mroop_kfold\u001b[0;34m(data_name, num_tree, modelname, visualize, num_cv, num_folds)\u001b[0m\n\u001b[1;32m     43\u001b[0m         bar2\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m modelname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMTGB\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 45\u001b[0m         train_mse, test_mse, root_split_proba_list \u001b[38;5;241m=\u001b[39m \u001b[43mpred_measure_performance_mtgb\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m                \u001b[49m\u001b[43mx_continuous_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_categorical_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m                \u001b[49m\u001b[43mx_continuous_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_categorical_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m                \u001b[49m\u001b[43mnum_tree\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_tree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m         train_mse_list\u001b[38;5;241m.\u001b[39mappend(train_mse)\n\u001b[1;32m     51\u001b[0m         test_mse_list\u001b[38;5;241m.\u001b[39mappend(test_mse)\n",
      "Cell \u001b[0;32mIn[14], line 22\u001b[0m, in \u001b[0;36mpred_measure_performance_mtgb\u001b[0;34m(x_continuous_train, x_categorical_train, y_train, x_continuous_test, x_categorical_test, y_test, num_tree)\u001b[0m\n\u001b[1;32m     15\u001b[0m build_inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mMTGB_model_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbuild_params\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_continuous_vecs\u001b[39m\u001b[38;5;124m'\u001b[39m: x_continuous_train,\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_categorical_vecs\u001b[39m\u001b[38;5;124m'\u001b[39m: x_categorical_train,\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_vec\u001b[39m\u001b[38;5;124m'\u001b[39m: y_train,\n\u001b[1;32m     20\u001b[0m }\n\u001b[1;32m     21\u001b[0m model \u001b[38;5;241m=\u001b[39m MTGB_model_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m](\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minit_inputs)\n\u001b[0;32m---> 22\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_metatrees\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbuild_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# model.calc_pred_dist()\u001b[39;00m\n\u001b[1;32m     25\u001b[0m hat_y_train \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mmake_prediction(\n\u001b[1;32m     26\u001b[0m         x_continuous_train,\n\u001b[1;32m     27\u001b[0m         x_categorical_train,\n\u001b[1;32m     28\u001b[0m         loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msquared\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     29\u001b[0m )\n",
      "File \u001b[0;32m~/GitHub/Gradient_Boosting_Meta_Tree/gradient_boosting_meta_tree/metatree/sum_of_metatrees.py:475\u001b[0m, in \u001b[0;36mSumOfMetaTreeLearnModel.build_metatrees\u001b[0;34m(self, x_continuous_vecs, x_categorical_vecs, y_vec, split_strategy, building_scheme, centerize_y, calc_residual, progress_bar, max_leaf_nodes, SklearnEnsembleObj, params_sklearn_ensemble, update_leaf_with_residual, XGBRegressorObj, params_xgb, given_split_rules_list)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m split_strategy \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    474\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m calc_residual:\n\u001b[0;32m--> 475\u001b[0m         training_error_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_metatrees_by_residual\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_strategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbuilding_scheme\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuilding_scheme\u001b[49m\u001b[43m,\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmax_leaf_nodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_leaf_nodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    476\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m training_error_list\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/GitHub/Gradient_Boosting_Meta_Tree/gradient_boosting_meta_tree/metatree/sum_of_metatrees.py:625\u001b[0m, in \u001b[0;36mSumOfMetaTreeLearnModel._build_metatrees_by_residual\u001b[0;34m(self, split_strategy, building_scheme, progress_bar, max_leaf_nodes)\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;66;03m# feature_subsample\u001b[39;00m\n\u001b[1;32m    602\u001b[0m \u001b[38;5;66;03m# if self.feature_subsample == 'all_features':\u001b[39;00m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;66;03m#     tmp_feature_candidates = self.c_feature_candidates\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;66;03m# else:\u001b[39;00m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;66;03m#     raise(ParameterFormatError,'feature_subsample=\\'all_features\\', \\'log2\\', \\'sqrt\\', or an int number are only supported in this moment.')\u001b[39;00m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhn_metatree_list[i] \u001b[38;5;241m=\u001b[39m MetaTreeLearnModel(\n\u001b[1;32m    610\u001b[0m     SubModel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mSubModel,\n\u001b[1;32m    611\u001b[0m     c_dim_continuous \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc_dim_continuous,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    623\u001b[0m     seed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed, \u001b[38;5;66;03m# TODO: rngをそのまま渡したい．\u001b[39;00m\n\u001b[1;32m    624\u001b[0m )\n\u001b[0;32m--> 625\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhn_metatree_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_continuous_vecs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtmp_indices\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_categorical_vecs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtmp_indices\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresidual_vec\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtmp_indices\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_criterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtmp_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbuilding_scheme\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_check\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_features\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_subsample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_leaf_nodes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_leaf_nodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhn_metatree_list[i]\u001b[38;5;241m.\u001b[39mcalc_pred_dist()\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_function \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msquared_error\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/GitHub/Gradient_Boosting_Meta_Tree/gradient_boosting_meta_tree/metatree/metatree_single_LearnModel.py:1255\u001b[0m, in \u001b[0;36mMetaTreeLearnModel.build\u001b[0;34m(self, x_continuous_vecs, x_categorical_vecs, y_vec, split_strategy, criterion, sample_weight, building_scheme, ignore_check, max_leaf_nodes, max_features, sklearn_tree, given_split_rules, xgb_tree_info)\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_posterior_submodel_node(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_node, x_continuous_vecs, x_categorical_vecs, y_vec,reset_param\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m building_scheme \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdepth_first\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m-> 1255\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_depth_first\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1256\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1257\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# rng = rng,\u001b[39;49;00m\n\u001b[1;32m   1258\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# x_train_mat = x_train_mat,\u001b[39;49;00m\n\u001b[1;32m   1259\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# y_train_vec = y_train_vec,\u001b[39;49;00m\n\u001b[1;32m   1260\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# splitter = splitter,\u001b[39;49;00m\n\u001b[1;32m   1262\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# max_depth = max_depth,\u001b[39;49;00m\n\u001b[1;32m   1263\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# min_samples_split = min_samples_split,\u001b[39;49;00m\n\u001b[1;32m   1264\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# min_samples_leaf = min_samples_leaf,\u001b[39;49;00m\n\u001b[1;32m   1265\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# max_features_int = max_features_int,\u001b[39;49;00m\n\u001b[1;32m   1266\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# max_leaf_nodes = max_leaf_nodes,\u001b[39;49;00m\n\u001b[1;32m   1267\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# min_criteria_decrease = min_criteria_decrease,\u001b[39;49;00m\n\u001b[1;32m   1268\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# h0_split = h0_split,\u001b[39;49;00m\n\u001b[1;32m   1269\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1270\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m building_scheme \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbreadth_first\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m   1271\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_breadth_first(\n\u001b[1;32m   1272\u001b[0m         split_strategy,\n\u001b[1;32m   1273\u001b[0m         \u001b[38;5;66;03m# rng = rng,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1284\u001b[0m         \u001b[38;5;66;03m# h0_split = h0_split,\u001b[39;00m\n\u001b[1;32m   1285\u001b[0m         )\n",
      "File \u001b[0;32m~/GitHub/Gradient_Boosting_Meta_Tree/gradient_boosting_meta_tree/metatree/metatree_single_LearnModel.py:1357\u001b[0m, in \u001b[0;36mMetaTreeLearnModel._build_depth_first\u001b[0;34m(self, split_strategy, criterion)\u001b[0m\n\u001b[1;32m   1355\u001b[0m     leaf_nodes_end\u001b[38;5;241m.\u001b[39mappend(node)\n\u001b[1;32m   1356\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m-> 1357\u001b[0m val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_split_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_continuous_vecs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_indices\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_categorical_vecs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_indices\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_vec\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_indices\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43msplit_strategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1359\u001b[0m     node\u001b[38;5;241m.\u001b[39mis_leaf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/GitHub/Gradient_Boosting_Meta_Tree/gradient_boosting_meta_tree/metatree/metatree_single_LearnModel.py:1626\u001b[0m, in \u001b[0;36mMetaTreeLearnModel._split_node\u001b[0;34m(self, node, sub_x_continuous_vecs, sub_x_categorical_vecs, sub_y_vec, split_strategy, criterion)\u001b[0m\n\u001b[1;32m   1624\u001b[0m     node\u001b[38;5;241m.\u001b[39m_split_rule[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m split_rule[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   1625\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m split_strategy \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m-> 1626\u001b[0m     split_rule, criterion_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_node_split_rule_best\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1627\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m split_rule[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;66;03m# No gain obtained by the split\u001b[39;00m\n\u001b[1;32m   1628\u001b[0m         \u001b[38;5;66;03m# self._update_posterior_submodel_node(node, sub_x_continuous_vecs, sub_x_categorical_vecs, sub_y_vec) # 子ノードでインダイス取得処理も行うため，全データを入力する必要あり?\u001b[39;00m\n\u001b[1;32m   1629\u001b[0m         \u001b[38;5;66;03m# self._update_posterior_hn_split_node(node) # XXX: サブモデルを複数回同じデータで更新していたためバグが存在．一旦コメントアウトしたがそのうち修正する\u001b[39;00m\n\u001b[1;32m   1630\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/GitHub/Gradient_Boosting_Meta_Tree/gradient_boosting_meta_tree/metatree/metatree_single_LearnModel.py:1468\u001b[0m, in \u001b[0;36mMetaTreeLearnModel._node_split_rule_best\u001b[0;34m(self, node, criterion)\u001b[0m\n\u001b[1;32m   1466\u001b[0m \u001b[38;5;66;03m# children_indices = [[] for _ in range(np.max(self.c_num_children_vec))]\u001b[39;00m\n\u001b[1;32m   1467\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m rule \u001b[38;5;129;01min\u001b[39;00m split_candidates: \u001b[38;5;66;03m# rule[0] -> feature, rule[1] -> threshold\u001b[39;00m\n\u001b[0;32m-> 1468\u001b[0m     val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_calc_gain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1470\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1471\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnode_criterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1472\u001b[0m \u001b[43m        \u001b[49m\u001b[43msub_x_continuous_vecs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1473\u001b[0m \u001b[43m        \u001b[49m\u001b[43msub_x_categorical_vecs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1474\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1475\u001b[0m \u001b[43m        \u001b[49m\u001b[43msub_y_vec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1476\u001b[0m \u001b[43m        \u001b[49m\u001b[43msub_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1477\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1478\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;241m>\u001b[39m best_val:\n\u001b[1;32m   1479\u001b[0m         best_val \u001b[38;5;241m=\u001b[39m val\n",
      "File \u001b[0;32m~/GitHub/Gradient_Boosting_Meta_Tree/gradient_boosting_meta_tree/metatree/metatree_single_LearnModel.py:1538\u001b[0m, in \u001b[0;36mMetaTreeLearnModel._calc_gain\u001b[0;34m(self, rule, node, node_criterion, sub_x_continuous_vecs, sub_x_categorical_vecs, criterion, sub_y_vec, sub_sample_weight)\u001b[0m\n\u001b[1;32m   1536\u001b[0m l_indice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_left_child_mask(rule,sub_x_continuous_vecs,sub_x_categorical_vecs,)\n\u001b[1;32m   1537\u001b[0m r_indice \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m~\u001b[39ml_indice\n\u001b[0;32m-> 1538\u001b[0m children_criterion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_calc_criterion_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msub_y_vec\u001b[49m\u001b[43m[\u001b[49m\u001b[43ml_indice\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msub_sample_weight\u001b[49m\u001b[43m[\u001b[49m\u001b[43ml_indice\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\\\n\u001b[1;32m   1539\u001b[0m                         \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calc_criterion_node(node, criterion, sub_y_vec[r_indice], sub_sample_weight[r_indice])\n\u001b[1;32m   1540\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m criterion\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msquared_error_leaf\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m   1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m node_criterion \u001b[38;5;241m-\u001b[39m children_criterion\n",
      "File \u001b[0;32m~/GitHub/Gradient_Boosting_Meta_Tree/gradient_boosting_meta_tree/metatree/metatree_single_LearnModel.py:1566\u001b[0m, in \u001b[0;36mMetaTreeLearnModel._calc_criterion_node\u001b[0;34m(self, node, criterion, y_vec, sample_weight)\u001b[0m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_calc_criterion_node\u001b[39m(\n\u001b[1;32m   1559\u001b[0m         \u001b[38;5;28mself\u001b[39m, \n\u001b[1;32m   1560\u001b[0m         node: _LearnNode, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1563\u001b[0m         sample_weight: ArrayLike,\n\u001b[1;32m   1564\u001b[0m     ):\n\u001b[1;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m criterion \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msquared_error_leaf\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m-> 1566\u001b[0m         val \u001b[38;5;241m=\u001b[39m _squared_error_with_weight(y_vec,\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_vec\u001b[49m\u001b[43m)\u001b[49m,sample_weight)\n\u001b[1;32m   1567\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m criterion \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msquared_error_meta\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m   1568\u001b[0m         val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calc_squared_error_meta(node,y_vec,sample_weight)\n",
      "File \u001b[0;32m~/miniconda3/envs/bayesml_dev_310/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504\u001b[0m, in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m   3501\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3502\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m mean(axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 3504\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_methods\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mean\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3505\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/bayesml_dev_310/lib/python3.10/site-packages/numpy/core/_methods.py:106\u001b[0m, in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m    102\u001b[0m arr \u001b[38;5;241m=\u001b[39m asanyarray(a)\n\u001b[1;32m    104\u001b[0m is_float16_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m rcount \u001b[38;5;241m=\u001b[39m \u001b[43m_count_reduce_items\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rcount \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m where \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m umr_any(rcount \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    108\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean of empty slice.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mRuntimeWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/bayesml_dev_310/lib/python3.10/site-packages/numpy/core/_methods.py:72\u001b[0m, in \u001b[0;36m_count_reduce_items\u001b[0;34m(arr, axis, keepdims, where)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m where \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;66;03m# no boolean mask given, calculate items according to axis\u001b[39;00m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 72\u001b[0m         axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(axis, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m     74\u001b[0m         axis \u001b[38;5;241m=\u001b[39m (axis,)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_cv = 3\n",
    "num_folds = 5\n",
    "visualize = False\n",
    "\n",
    "df_resume = pd.DataFrame()\n",
    "tqdm.write(f'num_cv: {num_cv}, num_folds: {num_folds}, visualize: {visualize}, num_tree: {num_tree}')\n",
    "with tqdm(total=len(DATA_NAMES), desc=\"Data\", leave=False) as pbar:\n",
    "    for data_name in DATA_NAMES:\n",
    "        x_continuous,x_categorical,y = load_data(data_name,DIR_DATA)\n",
    "        txt = f'{data_name}: {x_continuous.shape[0]} samples, {x_continuous.shape[1]+x_categorical.shape[1]} features'\n",
    "        pbar.set_postfix_str(txt)\n",
    "        res_dict = experiment(\n",
    "            data_name,\n",
    "            num_tree,\n",
    "            visualize,\n",
    "            num_cv,\n",
    "            num_folds,\n",
    "        )\n",
    "        pbar.update(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayesml_dev_310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
